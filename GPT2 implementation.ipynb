{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Step 1: Data Collection and Preprocessing\n",
    "stories_data = [...]  # List of human-written stories\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(stories_data)\n",
    "sequences = tokenizer.texts_to_sequences(stories_data)\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "sequences_padded = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "train_data = sequences_padded[:int(len(sequences_padded) * 0.8)]\n",
    "val_data = sequences_padded[int(len(sequences_padded) * 0.8):]\n",
    "\n",
    "# Step 2: Model Selection and Pretraining\n",
    "# Pretraining can be done using a generative AI model like GPT-3 or BERT\n",
    "# Fine-tune the model on the collected story dataset\n",
    "\n",
    "# Step 3: Objectives\n",
    "# Objective 1: Narrative Coherence and Flow\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "lstm_units = 128\n",
    "num_epochs = 10\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(units=lstm_units, return_sequences=True),\n",
    "    Attention(),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(train_data, epochs=num_epochs, validation_data=val_data)\n",
    "\n",
    "# Objective 2: Character Depth and Development\n",
    "character_vocab_size = len(tokenizer.word_index) + 1\n",
    "gru_units = 128\n",
    "\n",
    "character_model = Sequential([\n",
    "    Embedding(input_dim=character_vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(units=lstm_units, return_sequences=True),\n",
    "    GRU(units=gru_units, return_sequences=False),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "character_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "character_model.fit(train_data, epochs=num_epochs, validation_data=val_data)\n",
    "\n",
    "# Objective 3: Surprise and Creativity\n",
    "model_with_reg = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(units=lstm_units, return_sequences=True),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "model_with_reg.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model_with_reg.fit(train_data, epochs=num_epochs, validation_data=val_data, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)])\n",
    "\n",
    "# Step 4: Evaluation Metrics\n",
    "# Use both automatic metrics (e.g., BLEU, ROUGE) and human-centric evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your Excel file is named \"data.xlsx\"\n",
    "file_path = \"4000-Stories-with-sentiment-analysis.xlsx\"\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>length</th>\n",
       "      <th>title</th>\n",
       "      <th>text_no</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://americanliterature.com/author/eleanor-...</td>\n",
       "      <td>15044</td>\n",
       "      <td>Peace on Earth, Good-Will to Dogs</td>\n",
       "      <td>0</td>\n",
       "      <td>Eleanor Hallowell Abbott</td>\n",
       "      <td>PART I\\n\\nIf you don't like Christmas stories,...</td>\n",
       "      <td>0.592896</td>\n",
       "      <td>0.397839</td>\n",
       "      <td>0.569567</td>\n",
       "      <td>...</td>\n",
       "      <td>3.793141</td>\n",
       "      <td>3.837345</td>\n",
       "      <td>3.778354</td>\n",
       "      <td>-0.815515</td>\n",
       "      <td>-0.720440</td>\n",
       "      <td>-10.738245</td>\n",
       "      <td>-8.765683</td>\n",
       "      <td>0.875089</td>\n",
       "      <td>-10.176691</td>\n",
       "      <td>1.736791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://americanliterature.com/author/eleanor-...</td>\n",
       "      <td>10874</td>\n",
       "      <td>The Indiscreet Letter</td>\n",
       "      <td>1</td>\n",
       "      <td>Eleanor Hallowell Abbott</td>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>0.593563</td>\n",
       "      <td>0.381156</td>\n",
       "      <td>0.574662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309515</td>\n",
       "      <td>3.147870</td>\n",
       "      <td>0.635545</td>\n",
       "      <td>-0.334742</td>\n",
       "      <td>-0.751833</td>\n",
       "      <td>-3.957765</td>\n",
       "      <td>-0.385042</td>\n",
       "      <td>-6.485331</td>\n",
       "      <td>-4.579382</td>\n",
       "      <td>-1.580983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://americanliterature.com/author/achmed-a...</td>\n",
       "      <td>6922</td>\n",
       "      <td>An Act of Piety</td>\n",
       "      <td>2</td>\n",
       "      <td>Achmed Abdullah</td>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>0.583742</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.566515</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.559562</td>\n",
       "      <td>-1.365196</td>\n",
       "      <td>3.256023</td>\n",
       "      <td>-3.436836</td>\n",
       "      <td>-0.721138</td>\n",
       "      <td>-7.386739</td>\n",
       "      <td>-3.685618</td>\n",
       "      <td>-2.188498</td>\n",
       "      <td>2.970203</td>\n",
       "      <td>3.309226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://americanliterature.com/author/achmed-a...</td>\n",
       "      <td>4371</td>\n",
       "      <td>An Indian Jataka</td>\n",
       "      <td>3</td>\n",
       "      <td>Achmed Abdullah</td>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>0.605795</td>\n",
       "      <td>0.404819</td>\n",
       "      <td>0.569258</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.402253</td>\n",
       "      <td>-4.087686</td>\n",
       "      <td>-3.714201</td>\n",
       "      <td>-0.967430</td>\n",
       "      <td>-1.042184</td>\n",
       "      <td>1.208730</td>\n",
       "      <td>6.321670</td>\n",
       "      <td>-4.462947</td>\n",
       "      <td>-4.534634</td>\n",
       "      <td>4.136161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://americanliterature.com/author/achmed-a...</td>\n",
       "      <td>3413</td>\n",
       "      <td>Fear</td>\n",
       "      <td>4</td>\n",
       "      <td>Achmed Abdullah</td>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>0.545548</td>\n",
       "      <td>0.404478</td>\n",
       "      <td>0.546212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637324</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>-3.545210</td>\n",
       "      <td>2.767453</td>\n",
       "      <td>0.447380</td>\n",
       "      <td>0.102913</td>\n",
       "      <td>0.755849</td>\n",
       "      <td>-10.680321</td>\n",
       "      <td>-0.472589</td>\n",
       "      <td>-0.216070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  length  \\\n",
       "0           0  https://americanliterature.com/author/eleanor-...   15044   \n",
       "1           1  https://americanliterature.com/author/eleanor-...   10874   \n",
       "2           2  https://americanliterature.com/author/achmed-a...    6922   \n",
       "3           3  https://americanliterature.com/author/achmed-a...    4371   \n",
       "4           4  https://americanliterature.com/author/achmed-a...    3413   \n",
       "\n",
       "                               title  text_no                    author  \\\n",
       "0  Peace on Earth, Good-Will to Dogs        0  Eleanor Hallowell Abbott   \n",
       "1              The Indiscreet Letter        1  Eleanor Hallowell Abbott   \n",
       "2                    An Act of Piety        2           Achmed Abdullah   \n",
       "3                   An Indian Jataka        3           Achmed Abdullah   \n",
       "4                               Fear        4           Achmed Abdullah   \n",
       "\n",
       "                                               story   valence   arousal  \\\n",
       "0  PART I\\n\\nIf you don't like Christmas stories,...  0.592896  0.397839   \n",
       "1  The Railroad Journey was very long and slow. T...  0.593563  0.381156   \n",
       "2  His affair that night was prosy. He was intend...  0.583742  0.395598   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...  0.605795  0.404819   \n",
       "4  THE fact that the man whom he feared had died ...  0.545548  0.404478   \n",
       "\n",
       "   dominance  ...       290       291       292       293       294  \\\n",
       "0   0.569567  ...  3.793141  3.837345  3.778354 -0.815515 -0.720440   \n",
       "1   0.574662  ... -0.309515  3.147870  0.635545 -0.334742 -0.751833   \n",
       "2   0.566515  ... -9.559562 -1.365196  3.256023 -3.436836 -0.721138   \n",
       "3   0.569258  ... -6.402253 -4.087686 -3.714201 -0.967430 -1.042184   \n",
       "4   0.546212  ... -0.637324  0.034142 -3.545210  2.767453  0.447380   \n",
       "\n",
       "         295       296        297        298       299  \n",
       "0 -10.738245 -8.765683   0.875089 -10.176691  1.736791  \n",
       "1  -3.957765 -0.385042  -6.485331  -4.579382 -1.580983  \n",
       "2  -7.386739 -3.685618  -2.188498   2.970203  3.309226  \n",
       "3   1.208730  6.321670  -4.462947  -4.534634  4.136161  \n",
       "4   0.102913  0.755849 -10.680321  -0.472589 -0.216070  \n",
       "\n",
       "[5 rows x 318 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['story']=df.story\n",
    "df1['title']=df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['story'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['story']=df['story'][:2]\n",
    "df2['title']=df['title'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "        processed_text = ' '.join(filtered_tokens)\n",
    "        return processed_text\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Example usage\n",
    "df2['title'] = df2['title'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PART I\\n\\nIf you don't like Christmas stories,...</td>\n",
       "      <td>Peace Earth , Good-Will Dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Railroad Journey was very long and slow. T...</td>\n",
       "      <td>Indiscreet Letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>His affair that night was prosy. He was intend...</td>\n",
       "      <td>Act Piety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the tale which Jehan Tugluk Khan, a wi...</td>\n",
       "      <td>Indian Jataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THE fact that the man whom he feared had died ...</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  PART I\\n\\nIf you don't like Christmas stories,...   \n",
       "1  The Railroad Journey was very long and slow. T...   \n",
       "2  His affair that night was prosy. He was intend...   \n",
       "3  This is the tale which Jehan Tugluk Khan, a wi...   \n",
       "4  THE fact that the man whom he feared had died ...   \n",
       "\n",
       "                          title  \n",
       "0  Peace Earth , Good-Will Dogs  \n",
       "1             Indiscreet Letter  \n",
       "2                     Act Piety  \n",
       "3                 Indian Jataka  \n",
       "4                          Fear  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df2['title'].values\n",
    "y_train=df2['story'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lenovo\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Attention,Bidirectional, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['story'])\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    input_sequences = []\n",
    "    for line in df['story']:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    \n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "    label = to_categorical(label, num_classes=total_words)  # Convert labels to one-hot encoded format\n",
    "    return predictors, label, max_sequence_len, total_words, tokenizer\n",
    "\n",
    "\n",
    "def create_model(max_sequence_len, total_words):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(total_words, 128, input_length=max_sequence_len-1))\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Training\n",
    "def train_model(model, predictors, label):\n",
    "    model.fit(predictors, label, epochs=10, verbose=1)\n",
    "\n",
    "# Step 4: Generating Stories\n",
    "def generate_story(model, tokenizer, max_sequence_len, seed_text, next_words=100):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]  # Get predicted probabilities\n",
    "        predicted_index = np.argmax(predicted_probs)  # Get index of word with highest probability\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "predictors, label, max_sequence_len, total_words, tokenizer = preprocess_data(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = create_model(max_sequence_len, total_words)\n",
    "# train_model(model, predictors, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = \"fantasy adventure magic\"\n",
    "# generated_story = generate_story(model, tokenizer, max_sequence_len, seed_text=keywords)\n",
    "# print(generated_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset=['story'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " decoder_inputs (InputLayer)    [(None, 49)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_inputs (InputLayer)    [(None, 49)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 49, 256)      4352        ['encoder_inputs[0][0]',         \n",
      "                                                                  'decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            (None, 256)          525312      ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            (None, 49, 256)      525312      ['embedding_layer[1][0]',        \n",
      "                                                                  'encoder_lstm[0][0]',           \n",
      "                                                                  'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, 49, 17)       4369        ['decoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,059,345\n",
      "Trainable params: 1,059,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize text data\n",
    "tokenizer = Tokenizer(oov_token='<UNK>', filters='')\n",
    "tokenizer.fit_on_texts(df2['story'])\n",
    "\n",
    "# Define parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = 50  # Maximum sequence length for stories\n",
    "latent_dim = 256\n",
    "\n",
    "# Convert text data to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df2['story'])\n",
    "\n",
    "# Pad sequences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define input and target sequences\n",
    "input_sequences = padded_sequences[:, :-1]\n",
    "target_sequences = padded_sequences[:, 1:]\n",
    "\n",
    "# Define encoder inputs\n",
    "encoder_inputs = Input(shape=(max_length - 1,), name='encoder_inputs')\n",
    "\n",
    "# Define shared embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=latent_dim, name='embedding_layer')\n",
    "\n",
    "# Apply embedding layer to encoder input\n",
    "encoder_embedding = embedding_layer(encoder_inputs)\n",
    "\n",
    "# Define LSTM encoder\n",
    "encoder_lstm = LSTM(latent_dim, name='encoder_lstm')\n",
    "encoder_outputs = encoder_lstm(encoder_embedding)\n",
    "\n",
    "# Define decoder inputs\n",
    "decoder_inputs = Input(shape=(max_length - 1,), name='decoder_inputs')\n",
    "\n",
    "# Apply embedding layer to decoder input\n",
    "decoder_embedding = embedding_layer(decoder_inputs)\n",
    "\n",
    "# Define LSTM decoder\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, name='decoder_lstm')\n",
    "decoder_outputs = decoder_lstm(decoder_embedding, initial_state=[encoder_outputs, encoder_outputs])\n",
    "\n",
    "# Define dense layer for output\n",
    "decoder_dense = Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1089, 100)         5328600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1089, 150)         150600    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 53286)             5381886   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,961,486\n",
      "Trainable params: 10,961,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load the text data\n",
    "with open('cleaned_merged_fairy_tales_without_eos.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Text pre-processing\n",
    "# Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and label\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "y = np.array(y)\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "# checkpoint = ModelCheckpoint('model.h5', monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# history = model.fit(X, y, epochs=5, callbacks=[checkpoint], verbose=1)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(seed_text, next_words, max_sequence_len, model):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# # Example usage\n",
    "# model.save(f\"Models/Story_generator\")\n",
    "\n",
    "# seed_text = \"king queen empire\"\n",
    "# generated_text = generate_text(seed_text, 500, max_sequence_len, model)\n",
    "# print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " embedding (Embedding)       (None, 1089, 100)         5328600   \n",
    "                                                                 \n",
    " lstm (LSTM)                 (None, 1089, 150)         150600    \n",
    "                                                                 \n",
    " lstm_1 (LSTM)               (None, 100)               100400    \n",
    "                                                                 \n",
    " dense (Dense)               (None, 53286)             5381886   \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 10,961,486\n",
    "Trainable params: 10,961,486\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Epoch 1/5\n",
    "115078/115078 [==============================] - ETA: 0s - loss: 5.9098 - accuracy: 0.1351\n",
    "Epoch 00001: loss improved from inf to 5.90983, saving model to model.h5\n",
    "115078/115078 [==============================] - 12788s 111ms/step - loss: 5.9098 - accuracy: 0.1351\n",
    "Epoch 2/5\n",
    "115078/115078 [==============================] - ETA: 0s - loss: 5.5767 - accuracy: 0.1590\n",
    "Epoch 00002: loss improved from 5.90983 to 5.57669, saving model to model.h5\n",
    "115078/115078 [==============================] - 12786s 111ms/step - loss: 5.5767 - accuracy: 0.1590\n",
    "Epoch 3/5\n",
    "115078/115078 [==============================] - ETA: 0s - loss: 5.4434 - accuracy: 0.1674\n",
    "Epoch 00003: loss improved from 5.57669 to 5.44345, saving model to model.h5\n",
    "115078/115078 [==============================] - 12746s 111ms/step - loss: 5.4434 - accuracy: 0.1674\n",
    "Epoch 4/5\n",
    "115078/115078 [==============================] - ETA: 0s - loss: 5.3812 - accuracy: 0.1711\n",
    "Epoch 00004: loss improved from 5.44345 to 5.38123, saving model to model.h5\n",
    "115078/115078 [==============================] - 12641s 110ms/step - loss: 5.3812 - accuracy: 0.1711\n",
    "Epoch 5/5\n",
    "115078/115078 [==============================] - ETA: 0s - loss: 5.3384 - accuracy: 0.1733\n",
    "Epoch 00005: loss improved from 5.38123 to 5.33838, saving model to model.h5\n",
    "115078/115078 [==============================] - 12701s 110ms/step - loss: 5.3384 - accuracy: 0.1733\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Story_generator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Story_generator\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000026E5289E040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000026E3C9B2EB0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"Models/Story_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len, model, tokenizer):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a great deal of money and the little girl was very sorry for her and said to her husband and said to him and said to him and said to him and said to him and said to him and said to him and said to him and said to him and he was very sorry for him to do and he was very sorry to do so much that he was very sorry for him to do and he was very sorry to do so he was very sorry for his sake and said to him “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be afraid of it ” he said “i will not be\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Once upon a time, there was a\"\n",
    "generated_text = generate_text(seed_text, 500, max_sequence_len, model,tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "tokenizer = Tokenizer()\n",
    "# Provide the path to your saved model file\n",
    "model_path = 'Models/Story_generator'\n",
    "\n",
    "# Load the model\n",
    "model1 = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_text(seed_text, next_words, max_sequence_len, model, tokenizer):\n",
    "    generated_text = seed_text\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "        generated_text += \" \" + output_word\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"The Nightingale and the Rose\"\n",
    "# generated_text = generate_text(text, 500,max_sequence_len, model1, tokenizer)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder='generate a story on '\n",
    "# keywords='Write a story 500 words story on '\n",
    "\n",
    "# input_ids = tokenizer.encode(keywords, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def generate_story():\n",
    "    input_text = input_field.get(\"1.0\", \"end-1c\") \n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=1000, num_beams=5, no_repeat_ngram_size=2)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    output_field.delete(\"1.0\", \"end\")  \n",
    "    output_field.insert(\"1.0\", output_text) \n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Story Generator\")\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "style.theme_use('clam')  \n",
    "\n",
    "\n",
    "input_label = ttk.Label(root, text=\"Input:\")\n",
    "input_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "input_field = tk.Text(root, height=5, width=50, wrap=\"word\", font=(\"Arial\", 11))\n",
    "input_field.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "\n",
    "output_label = ttk.Label(root, text=\"Output:\")\n",
    "output_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "output_field = tk.Text(root, height=15, width=50, wrap=\"word\", font=(\"Arial\", 11))\n",
    "output_field.grid(row=3, column=0, padx=5, pady=5)\n",
    "\n",
    "\n",
    "generate_button = ttk.Button(root, text=\"Generate Story\", command=generate_story)\n",
    "generate_button.grid(row=4, column=0, padx=5, pady=10)\n",
    "\n",
    "\n",
    "root.columnconfigure(0, weight=1)\n",
    "root.rowconfigure(3, weight=1)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1477,   452, 26436,   285, 37325,  1228]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1477,   452, 26436,   285, 37325,  1228,    13,   198,   198,     1,\n",
       "            40,   716,   407,  1016,   284,  1560,   345,   644,   284,   466,\n",
       "           553,   339,   531,    13,   366,    40,   765,   345,   284,   760,\n",
       "           326,   345,   389,   407,  3436,    13,   314,   716,   994,   284,\n",
       "          1037,   345,    13,   921,   389,   262,   691,   530,   508,   460,\n",
       "          1037,   502,    13,  1002,   345,   466,   407,   765,   284,   467,\n",
       "           284,   262,  1644,    11,   345,   460,  1282,   284,   502,   290,\n",
       "          1560,   502,   644,   345,   765,    13,   887,   611,   345,   836,\n",
       "           470,   765,   502,   284,  1011,  1337,   286,   345,    11,   788,\n",
       "           345,   423,   645,  3572,   475,   284,  2652,   994,    13,   775,\n",
       "           389,   994,   329,   345,   290,   356,   481,   466,  2279,   287,\n",
       "           674,  1176,   284,   651,   345,   503,   286,   994,   526, 50256]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = model.generate(input_ids, max_length=1000, num_beams=5, no_repeat_ngram_size=2)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shivaji maharaj.\n",
      "\n",
      "\"I am not going to tell you what to do,\" he said. \"I want you to know that you are not alone. I am here to help you. You are the only one who can help me. If you do not want to go to the police, you can come to me and tell me what you want. But if you don't want me to take care of you, then you have no choice but to stay here. We are here for you and we will do everything in our power to get you out of here.\"\n"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
