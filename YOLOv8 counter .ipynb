{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4961e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea3ead0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.1.47'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6801a5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9627ba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30beac26",
   "metadata": {},
   "source": [
    "# Detect, track and count Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23349aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd yolov8_DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ac57944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "import colorsys\n",
    "import numpy as np\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# results = model(\"images/person.jpg\", save=True)\n",
    "\n",
    "\n",
    "\n",
    "# class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "# for result in results:\n",
    "#     boxes = result.boxes  # Boxes object for bbox outputs\n",
    "#     probs = result.probs  # Class probabilities for classification outputs\n",
    "#     cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "#     xyxy = boxes.xyxy\n",
    "#     xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "#     conf = boxes.conf\n",
    "#     print(cls)\n",
    "#     for class_index in cls:\n",
    "#         class_name = class_names[int(class_index)]\n",
    "#         print(\"Class:\", class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c7b6e",
   "metadata": {},
   "source": [
    "# DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "945f584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_sort.utils.parser import get_config\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.sort.tracker import Tracker\n",
    "\n",
    "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7'\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d74f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the video path\n",
    "video_path = '../conveyer.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09056afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "unique_track_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17aff2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 (no detections), 43.6ms\n",
      "Speed: 3.8ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 48.7ms\n",
      "Speed: 0.2ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.6ms\n",
      "Speed: 0.4ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 48.8ms\n",
      "Speed: 0.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 50.3ms\n",
      "Speed: 0.0ms preprocess, 50.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.4ms\n",
      "Speed: 0.0ms preprocess, 49.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 43.8ms\n",
      "Speed: 0.0ms preprocess, 43.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.9ms\n",
      "Speed: 0.0ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.5ms\n",
      "Speed: 0.0ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 60.8ms\n",
      "Speed: 0.0ms preprocess, 60.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 52.4ms\n",
      "Speed: 0.0ms preprocess, 52.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.1ms\n",
      "Speed: 0.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 53.1ms\n",
      "Speed: 0.0ms preprocess, 53.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 53.2ms\n",
      "Speed: 0.0ms preprocess, 53.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.9ms\n",
      "Speed: 0.0ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.5ms\n",
      "Speed: 0.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.0ms\n",
      "Speed: 0.0ms preprocess, 40.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 43.6ms\n",
      "Speed: 0.0ms preprocess, 43.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 48.1ms\n",
      "Speed: 15.6ms preprocess, 48.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.6ms\n",
      "Speed: 0.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 52.1ms\n",
      "Speed: 0.0ms preprocess, 52.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.4ms\n",
      "Speed: 15.4ms preprocess, 47.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 41.0ms\n",
      "Speed: 0.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.4ms\n",
      "Speed: 12.5ms preprocess, 39.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.9ms\n",
      "Speed: 7.1ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.8ms\n",
      "Speed: 12.5ms preprocess, 46.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 54.8ms\n",
      "Speed: 0.0ms preprocess, 54.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.5ms\n",
      "Speed: 0.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.9ms\n",
      "Speed: 0.0ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 44.9ms\n",
      "Speed: 0.0ms preprocess, 44.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 45.6ms\n",
      "Speed: 1.2ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 44.1ms\n",
      "Speed: 7.4ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 33.5ms\n",
      "Speed: 0.3ms preprocess, 33.5ms inference, 16.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 44.4ms\n",
      "Speed: 9.5ms preprocess, 44.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.8ms\n",
      "Speed: 0.0ms preprocess, 49.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.1ms\n",
      "Speed: 0.0ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 45.0ms\n",
      "Speed: 0.0ms preprocess, 45.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.8ms\n",
      "Speed: 0.0ms preprocess, 49.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 44.9ms\n",
      "Speed: 0.2ms preprocess, 44.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.8ms\n",
      "Speed: 0.0ms preprocess, 49.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 45.5ms\n",
      "Speed: 0.0ms preprocess, 45.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.4ms\n",
      "Speed: 0.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 48.2ms\n",
      "Speed: 13.5ms preprocess, 48.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.7ms\n",
      "Speed: 15.6ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 47.4ms\n",
      "Speed: 4.0ms preprocess, 47.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 50.0ms\n",
      "Speed: 0.0ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.9ms\n",
      "Speed: 0.0ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 58.5ms\n",
      "Speed: 0.0ms preprocess, 58.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 50.4ms\n",
      "Speed: 0.0ms preprocess, 50.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.1ms\n",
      "Speed: 0.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 49.7ms\n",
      "Speed: 0.0ms preprocess, 49.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 39.6ms\n",
      "Speed: 0.0ms preprocess, 39.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 51.5ms\n",
      "Speed: 0.0ms preprocess, 51.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 45.9ms\n",
      "Speed: 2.3ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 43.2ms\n",
      "Speed: 0.0ms preprocess, 43.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 49.3ms\n",
      "Speed: 0.0ms preprocess, 49.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 49.6ms\n",
      "Speed: 0.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 40.6ms\n",
      "Speed: 0.0ms preprocess, 40.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 37.9ms\n",
      "Speed: 5.0ms preprocess, 37.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 49.6ms\n",
      "Speed: 3.7ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 (no detections), 46.4ms\n",
      "Speed: 0.0ms preprocess, 46.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 46.4ms\n",
      "Speed: 0.0ms preprocess, 46.4ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.3ms\n",
      "Speed: 0.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.3ms\n",
      "Speed: 12.1ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.6ms\n",
      "Speed: 8.1ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 46.7ms\n",
      "Speed: 0.0ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 50.0ms\n",
      "Speed: 0.0ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 49.9ms\n",
      "Speed: 0.0ms preprocess, 49.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 33.5ms\n",
      "Speed: 7.4ms preprocess, 33.5ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 33.5ms\n",
      "Speed: 3.8ms preprocess, 33.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 51.1ms\n",
      "Speed: 0.0ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 51.9ms\n",
      "Speed: 0.0ms preprocess, 51.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 51.1ms\n",
      "Speed: 0.0ms preprocess, 51.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 48.5ms\n",
      "Speed: 1.1ms preprocess, 48.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 49.3ms\n",
      "Speed: 0.0ms preprocess, 49.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 39.0ms\n",
      "Speed: 0.0ms preprocess, 39.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 50.0ms\n",
      "Speed: 0.0ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 38.8ms\n",
      "Speed: 6.9ms preprocess, 38.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 55.6ms\n",
      "Speed: 0.0ms preprocess, 55.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 36.2ms\n",
      "Speed: 13.5ms preprocess, 36.2ms inference, 11.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.0ms\n",
      "Speed: 0.0ms preprocess, 47.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 33.6ms\n",
      "Speed: 9.1ms preprocess, 33.6ms inference, 15.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.2ms\n",
      "Speed: 14.1ms preprocess, 47.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 50.2ms\n",
      "Speed: 0.0ms preprocess, 50.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 45.2ms\n",
      "Speed: 0.0ms preprocess, 45.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 43.6ms\n",
      "Speed: 0.0ms preprocess, 43.6ms inference, 6.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 53.8ms\n",
      "Speed: 0.0ms preprocess, 53.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 45.8ms\n",
      "Speed: 11.6ms preprocess, 45.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 39.1ms\n",
      "Speed: 3.3ms preprocess, 39.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 46.1ms\n",
      "Speed: 9.2ms preprocess, 46.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 Object, 43.8ms\n",
      "Speed: 0.0ms preprocess, 43.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        model = YOLO(\"../runs/detect/train3/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "        results = model(frame, device='cuda:0', classes=0, conf=0.7)\n",
    "\n",
    "        class_names = ['Bottle_Cap']\n",
    "        object_count = 0\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes object for bbox outputs\n",
    "            probs = result.probs  # Class probabilities for classification outputs\n",
    "            cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "            xyxy = boxes.xyxy\n",
    "            conf = boxes.conf\n",
    "            xywh = boxes.xywh  # box with xywh format, (N, 4)\n",
    "            for class_index in cls:\n",
    "                class_name = class_names[int(class_index)]\n",
    "                object_count += 1\n",
    "                #print(\"Class:\", class_name)\n",
    "\n",
    "        pred_cls = np.array(cls)\n",
    "        conf = conf.detach().cpu().numpy()\n",
    "        xyxy = xyxy.detach().cpu().numpy()\n",
    "        bboxes_xywh = xywh\n",
    "        bboxes_xywh = xywh.cpu().numpy()\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "        \n",
    "        tracks = tracker.update(bboxes_xywh, conf, og_frame)\n",
    "        \n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            cv2.rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 2)\n",
    "\n",
    "            text_color = (0, 0, 0)  # Black color for text\n",
    "            cv2.putText(og_frame, f\"{class_name}-{track_id}\", (int(x1) + 10, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "\n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        person_count = len(unique_track_ids)\n",
    "\n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "        # Draw person count on frame\n",
    "        # cv2.putText(frame, f\"Bottle caps detected: {object_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(og_frame, f\"Cap Count: {person_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(og_frame, f\"Bottle caps detected: {object_count}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Append the frame to the list\n",
    "        frames.append(og_frame)\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Video\", og_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3bd418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de83711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
